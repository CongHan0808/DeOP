_BASE_: ../coco-stuff-164k-171/maskformer_R50_bs32_60k.yaml
MODEL:
  META_ARCHITECTURE: "ZeroShotMaskFormer"
  SEM_SEG_HEAD:
    NAME: "ZeroShotMaskFormerHead"
    NUM_CLASSES: 156 #only used in set criterion
    EMBEDDING_DIM: 512
    EMBED_LAYERS: 2
  CLIP_ADAPTER:
    PROMPT_LEARNER: "predefined"
    PREDEFINED_PROMPT_TEMPLATES: ["a sculpture of a {}."]
    #CLIP_MODEL_NAME: "ViT-B/16"
    CLIP_MODEL_NAME: "/mnt/dolphinfs/hdd_pool/docker/user/hadoop-vacv/hancong/code/pretrain/ov-seg/zsseg.baseline/weights/clip/ViT-B-16.pt"
    MASK_FILL: "mean"
    MASK_EXPAND_RATIO: 1.0
    MASK_THR: 0.5
    MASK_MATTING: False
    REGION_RESIZED: True
    CLIP_ENSEMBLE: True
DATASETS:
  TRAIN: ("coco_2017_train_stuff_base_sem_seg",)